# Bible Chat API Configuration
# Copy this file to .env and customize

# ===========================================
# LLM CONFIGURATION
# ===========================================

# Provider: ollama, claude, or openai
LLM_PROVIDER=ollama

# Model name (depends on provider)
# Ollama: llama3:8b, mistral:7b, phi3:medium
# Claude: claude-sonnet-4-20250514
LLM_MODEL=llama3:8b

# Generation parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024

# ===========================================
# OLLAMA CONFIGURATION (for local LLM)
# ===========================================

OLLAMA_HOST=http://localhost:11434

# ===========================================
# EMBEDDING CONFIGURATION
# ===========================================

# Provider: ollama or openai
EMBEDDING_PROVIDER=ollama

# Model for generating embeddings
EMBEDDING_MODEL=nomic-embed-text

# Vector dimensions (must match model output)
EMBEDDING_DIMENSIONS=768

# ===========================================
# DATABASE
# ===========================================

DATABASE_URL=postgresql://bible:bible123@localhost:5432/bibledb

# ===========================================
# EXTERNAL API KEYS (optional)
# ===========================================

# For Claude provider
# ANTHROPIC_API_KEY=sk-ant-...

# For OpenAI provider
# OPENAI_API_KEY=sk-...

# ===========================================
# APPLICATION
# ===========================================

DEBUG=true
APP_NAME="Bible Inspiration Chat"

# Chat settings
MAX_CONTEXT_VERSES=5
MAX_CONVERSATION_HISTORY=10
