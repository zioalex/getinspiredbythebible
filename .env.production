# Production environment variables
# For use with Cloudflare Tunnel

# Frontend - API URL (same domain, Cloudflare routes to correct port)
NEXT_PUBLIC_API_URL=https://getinspiredbythebible.ai4you.sh

# LLM Configuration
# mistral:7b - Similar quality to llama3:8b, better memory efficiency for 8GB GPU
# Alternatives: llama3.1:8b, qwen2:7b
LLM_PROVIDER=ollama
LLM_MODEL=mistral:7b
EMBEDDING_MODEL=nomic-embed-text
