# Bible Chat API Configuration
# Copy this file to .env and customize

# ===========================================
# LLM CONFIGURATION
# ===========================================

# Provider: ollama, claude, openrouter, or openai
LLM_PROVIDER=ollama

# Model name (depends on provider)
# Ollama: llama3:8b, mistral:7b, phi3:medium
# Claude: claude-sonnet-4-20250514
# OpenRouter: meta-llama/llama-3.1-8b-instruct:free, google/gemma-2-9b-it:free
LLM_MODEL=llama3:8b

# Generation parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1024

# ===========================================
# OLLAMA CONFIGURATION (for local LLM)
# ===========================================

OLLAMA_HOST=http://localhost:11434

# ===========================================
# EMBEDDING CONFIGURATION
# ===========================================

# Provider: ollama, openrouter, or openai
# Note: OpenRouter doesn't support embeddings, use ollama for embeddings
EMBEDDING_PROVIDER=ollama

# Model for generating embeddings
EMBEDDING_MODEL=nomic-embed-text

# Vector dimensions (must match model output)
EMBEDDING_DIMENSIONS=768

# ===========================================
# DATABASE
# ===========================================

DATABASE_URL=postgresql://bible:bible123@localhost:5432/bibledb  # pragma: allowlist secret

# ===========================================
# EXTERNAL API KEYS (optional)
# ===========================================

# For Claude provider
# ANTHROPIC_API_KEY=sk-ant-...

# For OpenRouter provider (free models available)
# Get your key at: https://openrouter.ai/keys
# OPENROUTER_API_KEY=sk-or-v1-...
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# OPENROUTER_MODEL=meta-llama/llama-3.1-8b-instruct:free

# For OpenAI provider
# OPENAI_API_KEY=sk-...

# ===========================================
# APPLICATION
# ===========================================

DEBUG=true
APP_NAME="Bible Inspiration Chat"

# Chat settings
MAX_CONTEXT_VERSES=5
MAX_CONVERSATION_HISTORY=10
